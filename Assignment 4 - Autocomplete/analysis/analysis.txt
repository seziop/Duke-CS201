Shivansh S. Mehta
sm682


Copy paste results from running benchmark
for each of three files (see code)

String fname = "data/threeletterwords.txt"; 

    init time: 0.005013	for BruteAutocomplete
    init time: 0.004059	for BinarySearchAutocomplete
    init time: 0.09495	for HashListAutocomplete

    search	size	#match	BruteAutoc	BinarySear	HashListAu
        17576	50	0.00448324	0.00461032	0.00039235
        17576	50	0.00116081	0.00308406	0.00000742
    a	676	50	0.00040858	0.00012475	0.00000464
    a	676	50	0.00054168	0.00026342	0.00000649
    b	676	50	0.00041693	0.00015119	0.00000696
    c	676	50	0.00038957	0.00013728	0.00000649
    g	676	50	0.00155826	0.00013078	0.00000557
    ga	26	50	0.00035664	0.00007699	0.00000557
    go	26	50	0.00049809	0.00007884	0.00000649
    gu	26	50	0.00047351	0.00006029	0.00000649
    x	676	50	0.00056533	0.00019849	0.00001762
    y	676	50	0.00069843	0.00020545	0.00000649
    z	676	50	0.00060522	0.00019432	0.00000742
    aa	26	50	0.00066922	0.00007096	0.00000835
    az	26	50	0.00022864	0.00005333	0.00000417
    za	26	50	0.00029449	0.00004406	0.00000696
    zz	26	50	0.00031072	0.00004267	0.00000696
    zqzqwwx	0	50	0.00200719	0.00003849	0.00001206

    size in bytes=246064	 for BruteAutocomplete
    size in bytes=246064	 for BinarySearchAutocomplete
    size in bytes=354276	 for HashListAutocomplete


fname = "data/fourletterwords.txt";
		
			
    init time: 0.07847	for BruteAutocomplete
    init time: 0.03539	for BinarySearchAutocomplete
    init time: 1.223	for HashListAutocomplete

    search	size	#match	BruteAutoc	BinarySear	HashListAu
        456976	50	0.01549123	0.02067755	0.00026667
        456976	50	0.00627571	0.00408718	0.00000649
    a	17576	50	0.00880973	0.00024719	0.00000557
    a	17576	50	0.00696857	0.00021704	0.00000557
    b	17576	50	0.00610179	0.00020035	0.00000603
    c	17576	50	0.00544417	0.00020406	0.00000649
    g	17576	50	0.00503281	0.00029635	0.00000788
    ga	676	50	0.00519652	0.00008162	0.00000557
    go	676	50	0.00500127	0.00005797	0.00000603
    gu	676	50	0.00498087	0.00006215	0.00000603
    x	17576	50	0.00488765	0.00021380	0.00000603
    y	17576	50	0.00524800	0.00024487	0.00000649
    z	17576	50	0.00502307	0.00021101	0.00000742
    aa	676	50	0.00517843	0.00005658	0.00000603
    az	676	50	0.00501008	0.00006122	0.00000603
    za	676	50	0.00526469	0.00005426	0.00000603
    zz	676	50	0.00468869	0.00004684	0.00000603
    zqzqwwx	0	50	0.00590840	0.00001855	0.00001345

    size in bytes=7311616	 for BruteAutocomplete
    size in bytes=7311616	 for BinarySearchAutocomplete
    size in bytes=11075636	 for HashListAutocomplete


fname = "data/alexa.txt";
		
    init time: 0.5847	for BruteAutocomplete
    init time: 1.742	for BinarySearchAutocomplete
    init time: 7.081	for HashListAutocomplete

    search	size	#match	BruteAutoc	BinarySear	HashListAu
    	1000000	50	0.03225319	0.02303210	0.00029078
    	1000000	50	0.01518097	0.00891130	0.00000742
    a	69464	50	0.01651152	0.00066180	0.00000696
    a	69464	50	0.01557100	0.00065299	0.00000649
    b	56037	50	0.01503535	0.00058156	0.00000696
    c	65842	50	0.01567581	0.00061959	0.00000696
    g	37792	50	0.01494028	0.00040580	0.00000649
    ga	6664	50	0.01607604	0.00017067	0.00000603
    go	6953	50	0.01519442	0.00013913	0.00000557
    gu	2782	50	0.01494445	0.00009229	0.00000557
    x	6717	50	0.01479094	0.00016417	0.00000603
    y	16765	50	0.01400625	0.00027316	0.00000696
    z	8780	50	0.01484845	0.00014423	0.00000557
    aa	718	50	0.01598746	0.00006215	0.00000603
    az	889	50	0.01521065	0.00006493	0.00000603
    za	1718	50	0.01449367	0.00007838	0.00000557
    zz	162	50	0.01470793	0.00004684	0.00000557
    zqzqwwx	0	50	0.01621193	0.00002597	0.00001994

    size in bytes=38204230	 for BruteAutocomplete
    size in bytes=38204230	 for BinarySearchAutocomplete
    size in bytes=98824414	 for HashListAutocomplete
		
--------------------------------

Paste results for # matches = 10000 with alexa.txt

    init time: 0.3953	for BruteAutocomplete
    init time: 1.529	for BinarySearchAutocomplete
    init time: 6.842	for HashListAutocomplete

    search	size	#match	BruteAutoc	BinarySear	HashListAu
        1000000	10000	0.04530083	0.06878881	0.00042899
        1000000	10000	0.01716868	0.04114222	0.00000928
    a	69464	10000	0.01554781	0.00998817	0.00000835
    a	69464	10000	0.01539245	0.01091477	0.00000881
    b	56037	10000	0.01480207	0.00902863	0.00000649
    c	65842	10000	0.01475570	0.00995477	0.00000603
    g	37792	10000	0.01477518	0.00788034	0.00000835
    ga	6664	10000	0.01438004	0.00194226	0.00000649
    go	6953	10000	0.01438607	0.00213519	0.00000696
    gu	2782	10000	0.01228984	0.00069751	0.00000603
    x	6717	10000	0.01306758	0.00180869	0.00000557
    y	16765	10000	0.01480671	0.00466040	0.00000649
    z	8780	10000	0.01410596	0.00258829	0.00000649
    aa	718	10000	0.01196335	0.00016788	0.00000557
    az	889	10000	0.01173425	0.00022539	0.00000603
    za	1718	10000	0.01117309	0.00041043	0.00000603
    zz	162	10000	0.01088741	0.00005333	0.00000603
    zqzqwwx	0	10000	0.01214747	0.00002551	0.00001391

    size in bytes=38204230	 for BruteAutocomplete
    size in bytes=38204230	 for BinarySearchAutocomplete
    size in bytes=98824414	 for HashListAutocomplete

Explain results: does number of matches have an effect
on the runtime?	
    
    The runtime results for 50 and 10,000 Matches are reproduced below:
    
    50 Matches ------
    
    init time: 0.5847	for BruteAutocomplete
    init time: 1.742	for BinarySearchAutocomplete
    init time: 7.081	for HashListAutocomplete
    
    10,000 Matches ------
    
    init time: 0.3953	for BruteAutocomplete
    init time: 1.529	for BinarySearchAutocomplete
    init time: 6.842	for HashListAutocomplete
    
    As can be seen, based on my results, the runtime went down in all three
    methods. However, the difference seems to be within the volatility between
    benchmark runs. In some runs the difference was larger while in others 50 
    matches was faster. So the effect of matches is not very conclusive.
    

--------------------------------

Explain why the last for loop in BruteAutocomplete.topMatches uses a LinkedList 
(and not an ArrayList) AND why the PriorityQueue uses Term.WeightOrder to get 
the top k heaviest matches -- rather than using Term.ReverseWeightOrder.

    1) The BruteAutocomplete.topMatches method uses a LinkedList as the .addFirst 
    function of Linked lists is more efficient (at O(N)) than the .add
    function of an array list (at O(N^2)). The rational lies in the fact that adding an 
    element in a LinkedList is simply adding a new Listnode and changing the 
    pointer after that, however adding an element in the first index of an ArrayList 
    requires shifting all current elements. 
    
    2) The priority Queue needs to ensure that the highest weighted elements
    remain at the top of the a size constrained queue. Hence, .weightOrder is 
    used instead of .ReverseWeightOrder which would have resulted in the
    queue order (descending) to be incorrect.

--------------------------------

Explain why HashListAutocomplete uses more memory than the 
other Autocomplete implementations. Be brief.

    The reasoning for this was outlined pretty well in the Medium article linked
    in the assignment description. While, other Autocomplete implementations 
    store a list of words once for the current prefix in question, HashListAutoComplete
    creates a new ArrayList for every prefix and each source word is added to
    to get a hashlist of words for each possible prefix.
    
    Now the problem with this method is that maintaining all these takes alot more
    memory, however the benefit is that for larger and larger collections of 
    source words (think the scale of google's database), the time it takes 
    for each addition retrieval gets shorter and shorter (This can be noticed in
    the benchmark results above). Note: that in our examples HashListAutocomplete 
    takes much more runtime because of high intitial runtime.
